{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TPA Simulation Remote Launcher ===\n",
      "Preparing files and submitting jobs to remote server...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import paramiko\n",
    "from scp import SCPClient\n",
    "import shutil\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# ==== TPA Simulation Remote Execution System ====\n",
    "print(\"=== TPA Simulation Remote Launcher ===\")\n",
    "print(\"Preparing files and submitting jobs to remote server...\")\n",
    "print()\n",
    "\n",
    "# Configuration\n",
    "server = \"tcad01.hep.manchester.ac.uk\"\n",
    "username = \"lihuazhen\"\n",
    "local_satellite_dir = \"Garfield_satellite\"\n",
    "remote_path = \"/tmp/\"\n",
    "bash_script_name = \"run_tpa_simulation.sh\"\n",
    "\n",
    "# Files to copy from Garfield_workplace\n",
    "source_dir = \"../Garfield_workplace\"\n",
    "files_to_copy = [\n",
    "    \"Diamond_4p.C\",\n",
    "    \"LUT.csv\", \n",
    "    \"run_tpa_simulation.sh\",\n",
    "    \"CMakeLists.txt\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Preparing local satellite directory...\n",
      "  → Clearing existing Garfield_satellite/\n",
      "  → Created fresh Garfield_satellite/\n",
      "  → Copying files from ../Garfield_workplace/\n",
      "    ✓ Diamond_4p.C (11,080 bytes)\n",
      "    ✓ LUT.csv (3,913,068 bytes)\n",
      "    ✓ run_tpa_simulation.sh (7,059 bytes)\n",
      "    ✓ CMakeLists.txt (472 bytes)\n",
      "  → Successfully copied 4/4 files\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==== Step 1: Prepare local satellite directory ====\n",
    "print(\"Step 1: Preparing local satellite directory...\")\n",
    "\n",
    "# Clear the satellite directory\n",
    "if os.path.exists(local_satellite_dir):\n",
    "    print(f\"  → Clearing existing {local_satellite_dir}/\")\n",
    "    shutil.rmtree(local_satellite_dir)\n",
    "\n",
    "# Create fresh satellite directory\n",
    "os.makedirs(local_satellite_dir, exist_ok=True)\n",
    "print(f\"  → Created fresh {local_satellite_dir}/\")\n",
    "\n",
    "# Copy required files from Garfield_workplace\n",
    "print(f\"  → Copying files from {source_dir}/\")\n",
    "copied_files = []\n",
    "for file_name in files_to_copy:\n",
    "    source_file = os.path.join(source_dir, file_name)\n",
    "    dest_file = os.path.join(local_satellite_dir, file_name)\n",
    "    \n",
    "    if os.path.exists(source_file):\n",
    "        shutil.copy2(source_file, dest_file)\n",
    "        file_size = os.path.getsize(dest_file)\n",
    "        print(f\"    ✓ {file_name} ({file_size:,} bytes)\")\n",
    "        copied_files.append(file_name)\n",
    "    else:\n",
    "        print(f\"    ✗ {file_name} (not found)\")\n",
    "\n",
    "print(f\"  → Successfully copied {len(copied_files)}/{len(files_to_copy)} files\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Uploading to remote server...\n",
      "  → Connecting to lihuazhen@tcad01.hep.manchester.ac.uk\n",
      "  ✓ SSH connection established\n",
      "  → Uploading Garfield_satellite/ to /tmp/\n",
      "  ✓ Upload completed\n",
      "  ✓ Made run_tpa_simulation.sh executable\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==== Step 2: Upload to remote server ====\n",
    "print(\"Step 2: Uploading to remote server...\")\n",
    "\n",
    "try:\n",
    "    # Establish SSH connection\n",
    "    print(f\"  → Connecting to {username}@{server}\")\n",
    "    ssh = paramiko.SSHClient()\n",
    "    ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "    ssh.connect(server, username=username)\n",
    "    print(\"  ✓ SSH connection established\")\n",
    "    \n",
    "    # Upload satellite directory\n",
    "    print(f\"  → Uploading {local_satellite_dir}/ to {remote_path}\")\n",
    "    with SCPClient(ssh.get_transport()) as scp:\n",
    "        scp.put(local_satellite_dir, remote_path, recursive=True)\n",
    "    print(\"  ✓ Upload completed\")\n",
    "    \n",
    "    # Make bash script executable\n",
    "    remote_script_path = f\"{remote_path}Garfield_satellite/{bash_script_name}\"\n",
    "    ssh.exec_command(f\"chmod +x {remote_script_path}\")\n",
    "    print(f\"  ✓ Made {bash_script_name} executable\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"  ✗ Error during upload: {e}\")\n",
    "    raise\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Executing TPA simulation on remote server...\n",
      "  → Executing: cd /tmp/Garfield_satellite && ./run_tpa_simulation.sh\n",
      "  → This may take several minutes to hours...\n",
      "  → You can monitor progress in real-time below:\n",
      "  ============================================================\n",
      "=== TPA Simulation Runner ===\n",
      "Compilation and batch job submission script\n",
      "\n",
      "Step 1: Compiling Diamond_4p...\n",
      "Cleaning previous build...\n",
      "  → Removed existing build directory\n",
      "  → Created fresh build directory\n",
      "Running cmake and make...\n",
      "-- The C compiler identification is GNU 8.5.0\n",
      "-- The CXX compiler identification is GNU 8.5.0\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Check for working C compiler: /usr/bin/cc - skipped\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "-- Found Vdt: /opt/root/include (found version \"0.4\") \n",
      "-- Found GSL: /usr/include (found version \"2.5\") \n",
      "-- Found OpenMP_C: -fopenmp (found version \"4.5\") \n",
      "-- Found OpenMP_CXX: -fopenmp (found version \"4.5\") \n",
      "-- Found OpenMP: TRUE (found version \"4.5\")  \n",
      "-- Configuring done (2.5s)\n",
      "-- Generating done (0.0s)\n",
      "-- Build files have been written to: /tmp/Garfield_satellite/build\n",
      "[ 50%] Building CXX object CMakeFiles/Diamond_4p.dir/Diamond_4p.C.o\n",
      "[100%] Linking CXX executable Diamond_4p\n",
      "[100%] Built target Diamond_4p\n",
      "✓ Compilation successful!\n",
      "\n",
      "Step 2: Setting up simulation grid...\n",
      "Grid configuration:\n",
      "  X range: 2.5 to 32.5 μm (7 points, step: 5.000000 μm)\n",
      "  Y range: 2.5 to 32.5 μm (7 points, step: 5.000000 μm)\n",
      "  Time step: 1.0 ns (21 points: 0 to 20.0 ns)\n",
      "  Total jobs: 49\n",
      "\n",
      "Results will be saved to: TPA_results_20250611_165644\n",
      "\n",
      "Step 3: Submitting simulation jobs to background...\n",
      "\n",
      "Submitting Job 1/49: x=2.500000 μm, y=2.500000 μm\n",
      "  → Job PID: 1538358, Log: TPA_results_20250611_165644/job_x2.500000_y2.500000.log\n",
      "Submitting Job 2/49: x=2.500000 μm, y=7.500000 μm\n",
      "  → Job PID: 1538365, Log: TPA_results_20250611_165644/job_x2.500000_y7.500000.log\n",
      "Submitting Job 3/49: x=2.500000 μm, y=12.500000 μm\n",
      "  → Job PID: 1538372, Log: TPA_results_20250611_165644/job_x2.500000_y12.500000.log\n",
      "Submitting Job 4/49: x=2.500000 μm, y=17.500000 μm\n",
      "  → Job PID: 1538380, Log: TPA_results_20250611_165644/job_x2.500000_y17.500000.log\n",
      "Submitting Job 5/49: x=2.500000 μm, y=22.500000 μm\n",
      "  → Job PID: 1538390, Log: TPA_results_20250611_165644/job_x2.500000_y22.500000.log\n",
      "Submitting Job 6/49: x=2.500000 μm, y=27.500000 μm\n",
      "  → Job PID: 1538403, Log: TPA_results_20250611_165644/job_x2.500000_y27.500000.log\n",
      "Submitting Job 7/49: x=2.500000 μm, y=32.500000 μm\n",
      "  → Job PID: 1538416, Log: TPA_results_20250611_165644/job_x2.500000_y32.500000.log\n",
      "Submitting Job 8/49: x=7.500000 μm, y=2.500000 μm\n",
      "  → Job PID: 1538434, Log: TPA_results_20250611_165644/job_x7.500000_y2.500000.log\n",
      "Submitting Job 9/49: x=7.500000 μm, y=7.500000 μm\n",
      "  → Job PID: 1538449, Log: TPA_results_20250611_165644/job_x7.500000_y7.500000.log\n",
      "Submitting Job 10/49: x=7.500000 μm, y=12.500000 μm\n",
      "  → Job PID: 1538463, Log: TPA_results_20250611_165644/job_x7.500000_y12.500000.log\n",
      "Submitting Job 11/49: x=7.500000 μm, y=17.500000 μm\n",
      "  → Job PID: 1538478, Log: TPA_results_20250611_165644/job_x7.500000_y17.500000.log\n",
      "Submitting Job 12/49: x=7.500000 μm, y=22.500000 μm\n",
      "  → Job PID: 1538489, Log: TPA_results_20250611_165644/job_x7.500000_y22.500000.log\n",
      "Submitting Job 13/49: x=7.500000 μm, y=27.500000 μm\n",
      "  → Job PID: 1538504, Log: TPA_results_20250611_165644/job_x7.500000_y27.500000.log\n",
      "Submitting Job 14/49: x=7.500000 μm, y=32.500000 μm\n",
      "  → Job PID: 1538520, Log: TPA_results_20250611_165644/job_x7.500000_y32.500000.log\n",
      "Submitting Job 15/49: x=12.500000 μm, y=2.500000 μm\n",
      "  → Job PID: 1538538, Log: TPA_results_20250611_165644/job_x12.500000_y2.500000.log\n",
      "Submitting Job 16/49: x=12.500000 μm, y=7.500000 μm\n",
      "  → Job PID: 1538552, Log: TPA_results_20250611_165644/job_x12.500000_y7.500000.log\n",
      "Submitting Job 17/49: x=12.500000 μm, y=12.500000 μm\n",
      "  → Job PID: 1538565, Log: TPA_results_20250611_165644/job_x12.500000_y12.500000.log\n",
      "Submitting Job 18/49: x=12.500000 μm, y=17.500000 μm\n",
      "  → Job PID: 1538584, Log: TPA_results_20250611_165644/job_x12.500000_y17.500000.log\n",
      "Submitting Job 19/49: x=12.500000 μm, y=22.500000 μm\n",
      "  → Job PID: 1538605, Log: TPA_results_20250611_165644/job_x12.500000_y22.500000.log\n",
      "Submitting Job 20/49: x=12.500000 μm, y=27.500000 μm\n",
      "  → Job PID: 1538627, Log: TPA_results_20250611_165644/job_x12.500000_y27.500000.log\n",
      "Submitting Job 21/49: x=12.500000 μm, y=32.500000 μm\n",
      "  → Job PID: 1538646, Log: TPA_results_20250611_165644/job_x12.500000_y32.500000.log\n",
      "Submitting Job 22/49: x=17.500000 μm, y=2.500000 μm\n",
      "  → Job PID: 1538670, Log: TPA_results_20250611_165644/job_x17.500000_y2.500000.log\n",
      "Submitting Job 23/49: x=17.500000 μm, y=7.500000 μm\n",
      "  → Job PID: 1538686, Log: TPA_results_20250611_165644/job_x17.500000_y7.500000.log\n",
      "Submitting Job 24/49: x=17.500000 μm, y=12.500000 μm\n",
      "  → Job PID: 1538707, Log: TPA_results_20250611_165644/job_x17.500000_y12.500000.log\n",
      "Submitting Job 25/49: x=17.500000 μm, y=17.500000 μm\n",
      "  → Job PID: 1538733, Log: TPA_results_20250611_165644/job_x17.500000_y17.500000.log\n",
      "Submitting Job 26/49: x=17.500000 μm, y=22.500000 μm\n",
      "  → Job PID: 1538746, Log: TPA_results_20250611_165644/job_x17.500000_y22.500000.log\n",
      "Submitting Job 27/49: x=17.500000 μm, y=27.500000 μm\n",
      "  → Job PID: 1538762, Log: TPA_results_20250611_165644/job_x17.500000_y27.500000.log\n",
      "Submitting Job 28/49: x=17.500000 μm, y=32.500000 μm\n",
      "  → Job PID: 1538778, Log: TPA_results_20250611_165644/job_x17.500000_y32.500000.log\n",
      "Submitting Job 29/49: x=22.500000 μm, y=2.500000 μm\n",
      "  → Job PID: 1538815, Log: TPA_results_20250611_165644/job_x22.500000_y2.500000.log\n",
      "Submitting Job 30/49: x=22.500000 μm, y=7.500000 μm\n",
      "  → Job PID: 1538841, Log: TPA_results_20250611_165644/job_x22.500000_y7.500000.log\n",
      "Submitting Job 31/49: x=22.500000 μm, y=12.500000 μm\n",
      "  → Job PID: 1538856, Log: TPA_results_20250611_165644/job_x22.500000_y12.500000.log\n",
      "Submitting Job 32/49: x=22.500000 μm, y=17.500000 μm\n",
      "  → Job PID: 1538870, Log: TPA_results_20250611_165644/job_x22.500000_y17.500000.log\n",
      "Submitting Job 33/49: x=22.500000 μm, y=22.500000 μm\n",
      "  → Job PID: 1538893, Log: TPA_results_20250611_165644/job_x22.500000_y22.500000.log\n",
      "Submitting Job 34/49: x=22.500000 μm, y=27.500000 μm\n",
      "  → Job PID: 1538918, Log: TPA_results_20250611_165644/job_x22.500000_y27.500000.log\n",
      "Submitting Job 35/49: x=22.500000 μm, y=32.500000 μm\n",
      "  → Job PID: 1538949, Log: TPA_results_20250611_165644/job_x22.500000_y32.500000.log\n",
      "Submitting Job 36/49: x=27.500000 μm, y=2.500000 μm\n",
      "  → Job PID: 1538965, Log: TPA_results_20250611_165644/job_x27.500000_y2.500000.log\n",
      "Submitting Job 37/49: x=27.500000 μm, y=7.500000 μm\n",
      "  → Job PID: 1538979, Log: TPA_results_20250611_165644/job_x27.500000_y7.500000.log\n",
      "Submitting Job 38/49: x=27.500000 μm, y=12.500000 μm\n",
      "  → Job PID: 1538995, Log: TPA_results_20250611_165644/job_x27.500000_y12.500000.log\n",
      "Submitting Job 39/49: x=27.500000 μm, y=17.500000 μm\n",
      "  → Job PID: 1539007, Log: TPA_results_20250611_165644/job_x27.500000_y17.500000.log\n",
      "Submitting Job 40/49: x=27.500000 μm, y=22.500000 μm\n",
      "  → Job PID: 1539033, Log: TPA_results_20250611_165644/job_x27.500000_y22.500000.log\n",
      "Submitting Job 41/49: x=27.500000 μm, y=27.500000 μm\n",
      "  → Job PID: 1539063, Log: TPA_results_20250611_165644/job_x27.500000_y27.500000.log\n",
      "Submitting Job 42/49: x=27.500000 μm, y=32.500000 μm\n",
      "  → Job PID: 1539076, Log: TPA_results_20250611_165644/job_x27.500000_y32.500000.log\n",
      "Submitting Job 43/49: x=32.500000 μm, y=2.500000 μm\n",
      "  → Job PID: 1539092, Log: TPA_results_20250611_165644/job_x32.500000_y2.500000.log\n",
      "Submitting Job 44/49: x=32.500000 μm, y=7.500000 μm\n",
      "  → Job PID: 1539108, Log: TPA_results_20250611_165644/job_x32.500000_y7.500000.log\n",
      "Submitting Job 45/49: x=32.500000 μm, y=12.500000 μm\n",
      "  → Job PID: 1539158, Log: TPA_results_20250611_165644/job_x32.500000_y12.500000.log\n",
      "Submitting Job 46/49: x=32.500000 μm, y=17.500000 μm\n",
      "  → Job PID: 1539185, Log: TPA_results_20250611_165644/job_x32.500000_y17.500000.log\n",
      "Submitting Job 47/49: x=32.500000 μm, y=22.500000 μm\n",
      "  → Job PID: 1539220, Log: TPA_results_20250611_165644/job_x32.500000_y22.500000.log\n",
      "Submitting Job 48/49: x=32.500000 μm, y=27.500000 μm\n",
      "  → Job PID: 1539257, Log: TPA_results_20250611_165644/job_x32.500000_y27.500000.log\n",
      "Submitting Job 49/49: x=32.500000 μm, y=32.500000 μm\n",
      "  → Job PID: 1539284, Log: TPA_results_20250611_165644/job_x32.500000_y32.500000.log\n",
      "\n",
      "All 49 jobs submitted to background!\n",
      "Job PIDs: 1538358 1538365 1538372 1538380 1538390 1538403 1538416 1538434 1538449 1538463 1538478 1538489 1538504 1538520 1538538 1538552 1538565 1538584 1538605 1538627 1538646 1538670 1538686 1538707 1538733 1538746 1538762 1538778 1538815 1538841 1538856 1538870 1538893 1538918 1538949 1538965 1538979 1538995 1539007 1539033 1539063 1539076 1539092 1539108 1539158 1539185 1539220 1539257 1539284\n",
      "\n",
      "Step 4: Waiting for all jobs to complete...\n",
      "You can monitor progress with: tail -f TPA_results_20250611_165644/*.log\n",
      "\n",
      "Progress: 0/49 jobs finished (0 successful, 0 failed, 49 still running)...\n",
      "Progress: 0/49 jobs finished (0 successful, 0 failed, 49 still running)...\n",
      "Progress: 0/49 jobs finished (0 successful, 0 failed, 49 still running)...\n",
      "Progress: 0/49 jobs finished (0 successful, 0 failed, 49 still running)...\n",
      "Progress: 0/49 jobs finished (0 successful, 0 failed, 49 still running)...\n",
      "Progress: 0/49 jobs finished (0 successful, 0 failed, 49 still running)...\n",
      "Progress: 0/49 jobs finished (0 successful, 0 failed, 49 still running)...\n",
      "Progress: 0/49 jobs finished (0 successful, 0 failed, 49 still running)...\n",
      "Progress: 0/49 jobs finished (0 successful, 0 failed, 49 still running)...\n",
      "Progress: 0/49 jobs finished (0 successful, 0 failed, 49 still running)...\n",
      "Progress: 0/49 jobs finished (0 successful, 0 failed, 49 still running)...\n",
      "Progress: 0/49 jobs finished (0 successful, 0 failed, 49 still running)...\n",
      "Progress: 0/49 jobs finished (0 successful, 0 failed, 49 still running)...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m channel\u001b[38;5;241m.\u001b[39mexit_status_ready():\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m exit_status \u001b[38;5;241m=\u001b[39m channel\u001b[38;5;241m.\u001b[39mrecv_exit_status()\n\u001b[1;32m     36\u001b[0m channel\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ==== Step 3: Execute simulation on remote server ====\n",
    "print(\"Step 3: Executing TPA simulation on remote server...\")\n",
    "\n",
    "try:\n",
    "    # Execute the bash script\n",
    "    remote_dir = f\"{remote_path}Garfield_satellite\"\n",
    "    command = f\"cd {remote_dir} && ./{bash_script_name}\"\n",
    "    \n",
    "    print(f\"  → Executing: {command}\")\n",
    "    print(\"  → This may take several minutes to hours...\")\n",
    "    print(\"  → You can monitor progress in real-time below:\")\n",
    "    print(\"  \" + \"=\"*60)\n",
    "    \n",
    "    # Execute command and stream output in real-time\n",
    "    transport = ssh.get_transport()\n",
    "    channel = transport.open_session()\n",
    "    channel.exec_command(command)\n",
    "    \n",
    "    # Stream output in real-time\n",
    "    while True:\n",
    "        if channel.recv_ready():\n",
    "            data = channel.recv(1024).decode('utf-8')\n",
    "            if data:\n",
    "                print(data, end='')\n",
    "        \n",
    "        if channel.recv_stderr_ready():\n",
    "            error_data = channel.recv_stderr(1024).decode('utf-8')\n",
    "            if error_data:\n",
    "                print(f\"[STDERR] {error_data}\", end='')\n",
    "        \n",
    "        if channel.exit_status_ready():\n",
    "            break\n",
    "        time.sleep(0.1)\n",
    "    \n",
    "    exit_status = channel.recv_exit_status()\n",
    "    channel.close()\n",
    "    \n",
    "    print(\"  \" + \"=\"*60)\n",
    "    if exit_status == 0:\n",
    "        print(\"  ✓ Simulation completed successfully!\")\n",
    "    else:\n",
    "        print(f\"  ✗ Simulation failed with exit status: {exit_status}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"  ✗ Error during execution: {e}\")\n",
    "    raise\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4: Downloading results from remote server...\n",
      "  → Created local results directory: ../Results/TPA_results_20250611_175144/\n",
      "  → Found result directories on remote server:\n",
      "    /tmp/Garfield_satellite/TPA_results_20250611_163545/:\n",
      "    total 8\n",
      "    drwxr-xr-x 2 lihuazhen atlas 4096 Jun 11 16:35 .\n",
      "    drwxr-xr-x 8 lihuazhen atlas 4096 Jun 11 16:51 ..\n",
      "    \n",
      "    /tmp/Garfield_satellite/TPA_results_20250611_163937/:\n",
      "    total 8\n",
      "    drwxr-xr-x 2 lihuazhen atlas 4096 Jun 11 16:39 .\n",
      "    drwxr-xr-x 8 lihuazhen atlas 4096 Jun 11 16:51 ..\n",
      "    \n",
      "    /tmp/Garfield_satellite/TPA_results_20250611_164325/:\n",
      "    total 8\n",
      "    drwxr-xr-x 2 lihuazhen atlas 4096 Jun 11 16:43 .\n",
      "    drwxr-xr-x 8 lihuazhen atlas 4096 Jun 11 16:51 ..\n",
      "    \n",
      "    /tmp/Garfield_satellite/TPA_results_20250611_164608/:\n",
      "    total 204\n",
      "    drwxr-xr-x 2 lihuazhen atlas 4096 Jun 11 16:46 .\n",
      "    drwxr-xr-x 8 lihuazhen atlas 4096 Jun 11 16:51 ..\n",
      "    -rw-r--r-- 1 lihuazhen atlas 1201 Jun 11 16:46 job_x12.500000_y12.500000.log\n",
      "  → Downloading from: /tmp/Garfield_satellite/job_x7.500000_y7.500000.log\n",
      "  ✗ Error during download: scp: /tmp/Garfield_satellite/job_x7.500000_y7.500000.log: No such file or directory\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==== Step 4: Download results ====\n",
    "print(\"Step 4: Downloading results from remote server...\")\n",
    "\n",
    "try:\n",
    "    # Create local results directory under Results/\n",
    "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    results_base_dir = \"../Results\"\n",
    "    # Ensure Results directory exists\n",
    "    os.makedirs(results_base_dir, exist_ok=True)\n",
    "    local_results_dir = os.path.join(results_base_dir, f\"TPA_results_{timestamp}\")\n",
    "    os.makedirs(local_results_dir, exist_ok=True)\n",
    "    print(f\"  → Created local results directory: {local_results_dir}/\")\n",
    "    \n",
    "    # Check what result directories exist on remote server\n",
    "    stdin, stdout, stderr = ssh.exec_command(f\"ls -la {remote_dir}/TPA_results_*/ 2>/dev/null | head -20\")\n",
    "    remote_dirs = stdout.read().decode().strip()\n",
    "    \n",
    "    if remote_dirs:\n",
    "        print(\"  → Found result directories on remote server:\")\n",
    "        print(\"    \" + remote_dirs.replace('\\n', '\\n    '))\n",
    "        \n",
    "        # Get the most recent results directory\n",
    "        stdin, stdout, stderr = ssh.exec_command(f\"ls -1 {remote_dir}/TPA_results_*/ | tail -1\")\n",
    "        latest_dir = stdout.read().decode().strip()\n",
    "        \n",
    "        if latest_dir:\n",
    "            remote_results_path = f\"{remote_dir}/{latest_dir.rstrip('/')}\"\n",
    "            print(f\"  → Downloading from: {remote_results_path}\")\n",
    "            \n",
    "            # Download results\n",
    "            with SCPClient(ssh.get_transport()) as scp:\n",
    "                scp.get(remote_results_path, local_results_dir, recursive=True)\n",
    "            \n",
    "            # Count downloaded files\n",
    "            downloaded_files = []\n",
    "            for root, dirs, files in os.walk(local_results_dir):\n",
    "                for file in files:\n",
    "                    if file.endswith('.txt') or file.endswith('.log'):\n",
    "                        downloaded_files.append(file)\n",
    "            \n",
    "            print(f\"  ✓ Downloaded {len(downloaded_files)} result files\")\n",
    "            print(f\"  → Results saved to: {local_results_dir}/\")\n",
    "            \n",
    "            # Show summary of downloaded files\n",
    "            tpa_files = [f for f in downloaded_files if f.startswith('TPA_simulation_')]\n",
    "            log_files = [f for f in downloaded_files if f.endswith('.log')]\n",
    "            \n",
    "            print(f\"    - TPA result files: {len(tpa_files)}\")\n",
    "            print(f\"    - Log files: {len(log_files)}\")\n",
    "        else:\n",
    "            print(\"  ✗ No result directories found\")\n",
    "    else:\n",
    "        print(\"  ⚠️  No result directories found on remote server\")\n",
    "        print(\"  → Check if simulation completed successfully\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"  ✗ Error during download: {e}\")\n",
    "    # Don't raise here, as we still want to cleanup\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5: Cleanup and summary...\n",
      "  ✓ SSH connection closed\n",
      "\n",
      "============================================================\n",
      "🎉 TPA Simulation Remote Execution Complete!\n",
      "============================================================\n",
      "📁 Results directory: ../Results/TPA_results_20250611_175144/\n",
      "📊 Total size: 0 bytes\n",
      "🔗 Remote server: lihuazhen@tcad01.hep.manchester.ac.uk\n",
      "📍 Remote path: /tmp/Garfield_satellite/\n",
      "\n",
      "💡 Next steps:\n",
      "   1. Check the downloaded result files\n",
      "   2. Analyze the TPA simulation data\n",
      "   3. Process the results in your analysis notebooks\n",
      "\n",
      "🕒 Execution completed at: 2025-06-11 17:51:50\n"
     ]
    }
   ],
   "source": [
    "# ==== Step 5: Cleanup and Summary ====\n",
    "print(\"Step 5: Cleanup and summary...\")\n",
    "\n",
    "try:\n",
    "    # Close SSH connection\n",
    "    ssh.close()\n",
    "    print(\"  ✓ SSH connection closed\")\n",
    "    \n",
    "    # Optional: Clean up remote files (uncomment if desired)\n",
    "    # print(\"  → Cleaning up remote files...\")\n",
    "    # ssh_cleanup = paramiko.SSHClient()\n",
    "    # ssh_cleanup.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "    # ssh_cleanup.connect(server, username=username)\n",
    "    # ssh_cleanup.exec_command(f\"rm -rf {remote_path}Garfield_satellite\")\n",
    "    # ssh_cleanup.close()\n",
    "    # print(\"  ✓ Remote files cleaned up\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"  ⚠️  Error during cleanup: {e}\")\n",
    "\n",
    "print()\n",
    "print(\"=\"*60)\n",
    "print(\"🎉 TPA Simulation Remote Execution Complete!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Final summary\n",
    "if 'local_results_dir' in locals() and os.path.exists(local_results_dir):\n",
    "    total_size = sum(os.path.getsize(os.path.join(root, file)) \n",
    "                    for root, dirs, files in os.walk(local_results_dir) \n",
    "                    for file in files)\n",
    "    print(f\"📁 Results directory: {local_results_dir}/\")\n",
    "    print(f\"📊 Total size: {total_size:,} bytes\")\n",
    "    print(f\"🔗 Remote server: {username}@{server}\")\n",
    "    print(f\"📍 Remote path: {remote_path}Garfield_satellite/\")\n",
    "else:\n",
    "    print(\"⚠️  No results were downloaded\")\n",
    "\n",
    "print(\"\\n💡 Next steps:\")\n",
    "print(\"   1. Check the downloaded result files\")\n",
    "print(\"   2. Analyze the TPA simulation data\") \n",
    "print(\"   3. Process the results in your analysis notebooks\")\n",
    "\n",
    "print(f\"\\n🕒 Execution completed at: {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huazhen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
